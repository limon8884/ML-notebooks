{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15BkQrrWYFm7"
   },
   "source": [
    "# Нейросети и вероятностные модели\n",
    "\n",
    "**Разработчик: Алексей Умнов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l68jl7LBO5R_"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aosokin/dl_cshse_ami/blob/master/2021-fall/homeworks_small/shw8/DL21-fall-shw8.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDvO627NPQBg",
    "outputId": "887270d8-e57e-4280-954e-9480429e8d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.py.1          100%[===================>]   2.10K  --.-KB/s    in 0s      \n",
      "pixelcnn.png.1      100%[===================>]  15.16K  --.-KB/s    in 0s      \n",
      "mask_no_center.png. 100%[===================>]     657  --.-KB/s    in 0s      \n",
      "mask_with_center.pn 100%[===================>]     663  --.-KB/s    in 0s      \n"
     ]
    }
   ],
   "source": [
    "!wget --quiet --show-progress \"https://raw.githubusercontent.com/aosokin/dl_cshse_ami/master/2021-fall/homeworks_small/shw8/utils.py\"\n",
    "!wget --quiet --show-progress \"https://raw.githubusercontent.com/aosokin/dl_cshse_ami/master/2021-fall/homeworks_small/shw8/pixelcnn.png\"\n",
    "!wget --quiet --show-progress \"https://raw.githubusercontent.com/aosokin/dl_cshse_ami/master/2021-fall/homeworks_small/shw8/mask_no_center.png\"\n",
    "!wget --quiet --show-progress \"https://raw.githubusercontent.com/aosokin/dl_cshse_ami/master/2021-fall/homeworks_small/shw8/mask_with_center.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4X4T4_l3YFm_"
   },
   "source": [
    "# Авторегрессионные модели\n",
    "\n",
    "На этом семинаре мы поработаем с авторегрессионными моделями на примере архитектуры PixelCNN. Мы обучим модель для задачи генерации изображений и для задачи дорисовывания недостающих частей изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZa_hAENYFnB"
   },
   "source": [
    "### LCD digits dataset\n",
    "\n",
    "В качестве примера мы возьмем датасет из простых LCD-цифр. Ниже приведен код, который его загружает и рисует примеры сэмплов.\n",
    "\n",
    "Источник датасета: https://gist.github.com/benjaminwilson/b25a321f292f98d74269b83d4ed2b9a8#file-lcd-digits-dataset-nmf-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "yXtp9nFhYFnD"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "kY1_pHlQYFnH",
    "outputId": "c6c396ba-7cc7-4fcc-cbaa-22f77aff5268"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import LcdDigits, IMAGE_WIDTH, IMAGE_HEIGHT\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_dataset = LcdDigits(BATCH_SIZE * 50)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "def show_as_image(image, figsize=(10, 5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    \n",
    "def batch_images_to_one(batches_images):\n",
    "    n_square_elements = int(np.sqrt(batches_images.shape[0]))\n",
    "    rows_images = np.split(np.squeeze(batches_images), n_square_elements)\n",
    "    return np.vstack([np.hstack(row_images) for row_images in rows_images])\n",
    "\n",
    "for batch, _ in train_loader:\n",
    "    show_as_image(batch_images_to_one(batch[:25]), figsize=(10, 10))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEVaGINYYFnL"
   },
   "source": [
    "Здесь специально выбран простой датасет, так как вероятностные модели обычно требуют больших ресурсов. Также обратите внимание, что хотя данные очень простые (фактически всего 10 разных сэмплов), они находятся в пространстве значительно большей размерности ($2^{8 \\times 13}$). Мы будем подавать модели сырые пиксели на вход, и будем хотеть, чтобы она нашла в них правильные зависимости и научилась строить только валидные изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJzlYXm8YFnM"
   },
   "source": [
    "### PixelCNN\n",
    "\n",
    "Коротко вспомним, что такое PixelCNN. Авторегрессионные модели в общем виде моделируют распределения на векторах $x = (x_1, \\ldots, x_N)$ в виде:\n",
    "\n",
    "$$\n",
    "    p(x) = \\prod_{i=1}^{N} p(x_i \\mid x_1, \\ldots, x_{i-1}).\n",
    "$$\n",
    "\n",
    "Распределения $p(x_i \\mid x_1, \\ldots, x_{i-1})$ можно моделировать при помощи нейронных сетей, которые получают на вход значения $x_1, \\ldots, x_{i-1}$ и выдают распределение вероятностей для значений $x_i$. Так как входов здесь переменное число, можно использовать рекуррентные сети (например, PixelRNN), но неплохо работает и более простая модель &mdash; PixelCNN, &mdash; которая подает на вход не все значения $x_1, \\ldots, x_{i-1}$, а только соседние на некотором расстоянии с помощью сверточных слоев.\n",
    "\n",
    "![pixelcnn](https://github.com/aosokin/dl_cshse_ami/blob/master/2021-fall/homeworks_small/shw8/pixelcnn.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rGLrAqSYFnN"
   },
   "source": [
    "Для того, чтобы для данного пикселя подавать на вход только значения идущие ранее, вместо обычных сверток нужно использовать маскированные свертки. Напишите недостающий код, чтобы создать соответствующие маски и потом сделайте из них слой для pytorch. Такие слои можно добавлять последовательно, сохраняя корректные зависимости, при этом во всех слоях кроме первого можно использовать центральный пиксель. У вас должны получаться вот такие маски (с `include_center=False` и с `include_center=True` соответственно):\n",
    "\n",
    "![](https://github.com/aosokin/dl_cshse_ami/blob/master/2021-fall/homeworks_small/shw8/mask_with_center.png?raw=1)\n",
    "![](https://github.com/aosokin/dl_cshse_ami/blob/master/2021-fall/homeworks_small/shw8/mask_no_center.png?raw=1)\n",
    "\n",
    "Hint: можно умножить на маску не входы, а веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "dn8qDNBbYFnO"
   },
   "outputs": [],
   "source": [
    "def causal_mask(width, height, starting_point):\n",
    "    \n",
    "    # YOUR CODE\n",
    "    ar = np.arange(width * height).reshape(height, width)\n",
    "    sp = starting_point[0] * width + starting_point[1]\n",
    "    mask = ar <= sp\n",
    "    return mask\n",
    "\n",
    "def conv_mask(height, width, include_center=False):\n",
    "    return torch.tensor(1.0 * causal_mask(\n",
    "        width, height, \n",
    "        starting_point=(height//2, width//2 + include_center - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "-eASPxssYFnS"
   },
   "outputs": [],
   "source": [
    "class MaskedConv2d(nn.Module):\n",
    "    def __init__(self, include_center, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        ks = kwargs['kernel_size']\n",
    "        self.register_buffer('mask', conv_mask(ks, ks, include_center=include_center))\n",
    "        # self.mask = conv_mask(ks, ks, include_center=include_center)\n",
    "        self.conv = nn.Conv2d(**kwargs)\n",
    "\n",
    "    # YOUR CODE\n",
    "    def forward(self, input):\n",
    "      self.conv.weight.data *= self.mask\n",
    "      return self.conv(input)\n",
    "      # return super().forward(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQFi3EZpYFnW"
   },
   "source": [
    "Теперь соберите сеть с несколькими слоями маскированных сверток и обучите ее.\n",
    "\n",
    "Hint 1: в задаче хорошо помогает сверточный слой 1x1 в конце.\n",
    "\n",
    "Hint 2: если ошибиться и нарушить казуальность (т.е. сделать зависимости вперед), то обучаться будет хорошо, а генерировать плохо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KpmWX_4hO7ON",
    "outputId": "72a60211-9a36-467c-c186-f56a9c28f9f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedConv2d(\n",
       "  (conv): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaskedConv2d(include_center=False, in_channels=1, out_channels=4, kernel_size=5, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "NalcDVxPYFnX"
   },
   "outputs": [],
   "source": [
    "N_PIXELS_OUT = 2 # binary 0/1 pixels\n",
    "class PixelCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "    # YOUR CODE\n",
    "        self.layers = nn.Sequential(*[\n",
    "            # MaskedConv2d(1, n_channels, kernel_size, padding, include_center=False),\n",
    "            MaskedConv2d(include_center=False, in_channels=1, out_channels=n_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(n_channels),\n",
    "            nn.ReLU(),\n",
    "            MaskedConv2d(include_center=True, in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(n_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=N_PIXELS_OUT, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(N_PIXELS_OUT)\n",
    "        ])         \n",
    "        \n",
    "    def forward(self, x):\n",
    "        pixel_logits = self.layers(x)\n",
    "        return pixel_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "-MOsZ5dyYFna"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 25\n",
    "LR = 0.005\n",
    "\n",
    "cnn = PixelCNN(n_channels=4, kernel_size=7, padding=3)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nek5rwLIYFne"
   },
   "source": [
    "Обратите внимание, что полученной сети достаточно подать на вход изображение, и на выходе получится распределение для значений каждого пикселя. Осталось только минимизировать кросс-энтропию этих значений и пикселей примеров в выборке. В случае успеха итоговая кросс-энтропия будет около 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aO-RlnLEYFnf",
    "outputId": "2b40d474-9954-49ad-e0cd-ee37407c3d66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.7753\n",
      "Epoch [2/25], Loss: 0.2488\n",
      "Epoch [3/25], Loss: 0.1508\n",
      "Epoch [4/25], Loss: 0.1136\n",
      "Epoch [5/25], Loss: 0.0950\n",
      "Epoch [6/25], Loss: 0.0855\n",
      "Epoch [7/25], Loss: 0.0776\n",
      "Epoch [8/25], Loss: 0.0733\n",
      "Epoch [9/25], Loss: 0.0703\n",
      "Epoch [10/25], Loss: 0.0679\n",
      "Epoch [11/25], Loss: 0.0662\n",
      "Epoch [12/25], Loss: 0.0647\n",
      "Epoch [13/25], Loss: 0.0629\n",
      "Epoch [14/25], Loss: 0.0616\n",
      "Epoch [15/25], Loss: 0.0600\n",
      "Epoch [16/25], Loss: 0.0555\n",
      "Epoch [17/25], Loss: 0.0465\n",
      "Epoch [18/25], Loss: 0.0444\n",
      "Epoch [19/25], Loss: 0.0439\n",
      "Epoch [20/25], Loss: 0.0433\n",
      "Epoch [21/25], Loss: 0.0427\n",
      "Epoch [22/25], Loss: 0.0420\n",
      "Epoch [23/25], Loss: 0.0414\n",
      "Epoch [24/25], Loss: 0.0411\n",
      "Epoch [25/25], Loss: 0.0405\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # YOUR CODE\n",
    "        output = cnn(images)\n",
    "        out = F.softmax(output)[:, 1, :, :].unsqueeze(1)\n",
    "        loss = F.binary_cross_entropy(out, images)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, N_EPOCHS, loss.data.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU-ZL85-YFnj"
   },
   "source": [
    "При генерации изображений можно начинать с пустого изображения, а можно подавать какие-то начальные пиксели. Допишите функцию генерации и проверьте ее для задачи генерации (на вход пустое изображения) и для задачи дорисовывания (на вход - верхняя часть изображения).\n",
    "\n",
    "У вас должны получиться разумные изображения цифр, допускается небольшая доля \"плохих\" изображений.\n",
    "\n",
    "*Упражнение:* почему при одинаковых пустых входных изображениях получаются разные изображения на выходе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1iEljgXO-iz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "z1o9I-9iYFnk",
    "outputId": "2390ad91-9e14-48b7-d3be-aa5edf7eaa5d"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-26b700e9f57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mshow_as_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_images_to_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-e6acfc916f60>\u001b[0m in \u001b[0;36mshow_as_image\u001b[0;34m(image, figsize)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_as_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (20, 130, 8) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_samples(n_samples, starting_point=(0, 0), starting_image=None):\n",
    "\n",
    "    samples = torch.from_numpy(\n",
    "        starting_image if starting_image is not None else \n",
    "        np.zeros((n_samples * n_samples, 1, IMAGE_HEIGHT, IMAGE_WIDTH))).float()\n",
    "\n",
    "    cnn.train(False)\n",
    "    \n",
    "    # YOUR CODE\n",
    "\n",
    "    # Это не успел, сорян(\n",
    "        \n",
    "        \n",
    "    out = cnn(samples).detach()\n",
    "    \n",
    "    return out.numpy()\n",
    "\n",
    "\n",
    "show_as_image(batch_images_to_one(generate_samples(n_samples=10)), figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZPqF6x_YFno"
   },
   "outputs": [],
   "source": [
    "from utils import random_digits\n",
    "\n",
    "n_images = 10\n",
    "starting_point = (4, 3)\n",
    "\n",
    "mask = causal_mask(IMAGE_HEIGHT, IMAGE_WIDTH, starting_point)\n",
    "\n",
    "starting_images = digits_list = [random_digits(fixed_label=d)[0] for d in range(10)]\n",
    "batch_starting_images = np.expand_dims(np.stack([i * mask for i in starting_images] * n_images), axis=1)\n",
    "\n",
    "samples = generate_samples(n_images, starting_image=batch_starting_images, starting_point=starting_point)\n",
    "\n",
    "show_as_image(np.hstack([(1 + mask) * i for i in starting_images]), figsize=(10, 10))\n",
    "\n",
    "show_as_image(\n",
    "    batch_images_to_one((samples * (1 + mask))),\n",
    "    figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEj0kKlPYFnr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Копия блокнота \"DL21-fall-shw8.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
