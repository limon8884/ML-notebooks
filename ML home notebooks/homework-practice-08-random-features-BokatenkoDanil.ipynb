{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 05.02.2021\n",
    "\n",
    "Мягкий дедлайн: 01:59MSK 21.02.2021\n",
    "\n",
    "Жесткий дедлайн: 01:59MSK 24.02.2021\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier as LGBM\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from scipy.linalg import qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg', num_samples=int(1e6)):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        self.num_samples = num_samples\n",
    "        self.model = None\n",
    "        self.pca = None\n",
    "        self.q = None\n",
    "        self.b = None\n",
    "        self.w = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        if self.use_PCA:\n",
    "            self.pca = PCA(n_components = self.new_dim)\n",
    "            X_new = self.pca.fit_transform(X)\n",
    "        else:\n",
    "            self.new_dim = X.shape[1]\n",
    "        print('PCA done!')\n",
    "        \n",
    "        ind1_ = (np.random.choice(len(X_new), self.num_samples))\n",
    "        ind2_ = (np.random.choice(len(X_new), self.num_samples))\n",
    "        ind1 = ind1_[ind1_ != ind2_]\n",
    "        ind2 = ind2_[ind1_ != ind2_]\n",
    "        self.q = np.median(((X_new[ind1] - X_new[ind2])**2).sum(axis=1))**0.5 #это сигма\n",
    "        \n",
    "        self.w = np.random.normal(scale=1 / self.q, size=(self.n_features, self.new_dim)) #это матрица весов w\n",
    "        self.b = np.random.uniform(low=-math.pi, high=math.pi, size=self.n_features) #это ветор весов b\n",
    "        \n",
    "        phi = np.cos(self.w @ X_new.T + np.repeat(self.b.reshape(-1, 1), len(X_new), axis=1)).T #это итоговые новые признаки\n",
    "        \n",
    "        print('Start fitting!')\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression()\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = SVC()\n",
    "        self.model.fit(phi, y)\n",
    "        #raise NotImplementedError\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        X_new = X.copy()\n",
    "        if self.use_PCA:\n",
    "            X_new = self.pca.transform(X)\n",
    "        phi = np.cos(self.w @ X_new.T + np.repeat(self.b.reshape(-1, 1), len(X_new), axis=1)).T\n",
    "        if self.classifier == 'logreg':\n",
    "            return self.model.predict_proba(phi)\n",
    "        elif self.classifier == 'svm':\n",
    "            return softmax(self.model.decision_function(phi))\n",
    "        #raise NotImplementedError\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        X_new = X.copy()\n",
    "        if self.use_PCA:\n",
    "            X_new = self.pca.transform(X)\n",
    "        phi = np.cos(self.w @ X_new.T + np.repeat(self.b.reshape(-1, 1), len(X_new), axis=1)).T\n",
    "        return self.model.predict(phi)\n",
    "        #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFFPipeline()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RFFPipeline()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут сдохнуть можно ждать иногда, поэтому на всякий случай будем брать 20% обуч выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.choice(len(x_train), int(len(x_train) * 0.2), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qN8LUlJgK-hV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_train[ind], y_train[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFFPipeline(classifier='svm')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_svm = RFFPipeline(classifier='svm')\n",
    "kernel_svm.fit(x_train[ind], y_train[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, svm.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8414"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, kernel_svm.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем, все 3 дали примерно одинаковые резы. \n",
    "Но так-то svm на начальных признаках оказался лучше почему-то, чем на подготовленных (навреное при PCA теряем слишком много инфы). RFF на логреге дал результат чуть получше, но там и обучающая выборка в 5 раз больше была. Так-то, я думаю, примерно тот же эффект был бы.\n",
    "Дальше про бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 50)\n",
    "x_train_new = pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.47801521\n",
      "bestIteration = 49\n",
      "\n",
      "0:\tloss: 1.4780152\tbest: 1.4780152 (0)\ttotal: 7.3s\tremaining: 3m 31s\n",
      "\n",
      "bestTest = 0.6008116335\n",
      "bestIteration = 49\n",
      "\n",
      "1:\tloss: 0.6008116\tbest: 0.6008116 (1)\ttotal: 14.5s\tremaining: 3m 23s\n",
      "\n",
      "bestTest = 0.6272964316\n",
      "bestIteration = 43\n",
      "\n",
      "2:\tloss: 0.6272964\tbest: 0.6008116 (1)\ttotal: 20.9s\tremaining: 3m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 9.609378409\n",
      "bestIteration = 0\n",
      "\n",
      "3:\tloss: 9.6093784\tbest: 0.6008116 (1)\ttotal: 27.1s\tremaining: 2m 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 96.03227356\n",
      "bestIteration = 0\n",
      "\n",
      "4:\tloss: 96.0322736\tbest: 0.6008116 (1)\ttotal: 33.5s\tremaining: 2m 47s\n",
      "\n",
      "bestTest = 1.155178172\n",
      "bestIteration = 99\n",
      "\n",
      "5:\tloss: 1.1551782\tbest: 0.6008116 (1)\ttotal: 46s\tremaining: 3m 4s\n",
      "\n",
      "bestTest = 0.4872124526\n",
      "bestIteration = 99\n",
      "\n",
      "6:\tloss: 0.4872125\tbest: 0.4872125 (6)\ttotal: 58.8s\tremaining: 3m 13s\n",
      "\n",
      "bestTest = 0.601209537\n",
      "bestIteration = 86\n",
      "\n",
      "7:\tloss: 0.6012095\tbest: 0.4872125 (6)\ttotal: 1m 10s\tremaining: 3m 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 9.609378409\n",
      "bestIteration = 0\n",
      "\n",
      "8:\tloss: 9.6093784\tbest: 0.4872125 (6)\ttotal: 1m 23s\tremaining: 3m 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 96.03227356\n",
      "bestIteration = 0\n",
      "\n",
      "9:\tloss: 96.0322736\tbest: 0.4872125 (6)\ttotal: 1m 35s\tremaining: 3m 10s\n",
      "\n",
      "bestTest = 0.9708719727\n",
      "bestIteration = 149\n",
      "\n",
      "10:\tloss: 0.9708720\tbest: 0.4872125 (6)\ttotal: 1m 54s\tremaining: 3m 17s\n",
      "\n",
      "bestTest = 0.446492127\n",
      "bestIteration = 149\n",
      "\n",
      "11:\tloss: 0.4464921\tbest: 0.4464921 (11)\ttotal: 2m 13s\tremaining: 3m 19s\n",
      "\n",
      "bestTest = 0.6009202077\n",
      "bestIteration = 125\n",
      "\n",
      "12:\tloss: 0.6009202\tbest: 0.4464921 (11)\ttotal: 2m 31s\tremaining: 3m 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 9.609378409\n",
      "bestIteration = 0\n",
      "\n",
      "13:\tloss: 9.6093784\tbest: 0.4464921 (11)\ttotal: 2m 49s\tremaining: 3m 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 96.03227356\n",
      "bestIteration = 0\n",
      "\n",
      "14:\tloss: 96.0322736\tbest: 0.4464921 (11)\ttotal: 3m 8s\tremaining: 3m 8s\n",
      "\n",
      "bestTest = 0.858749035\n",
      "bestIteration = 199\n",
      "\n",
      "15:\tloss: 0.8587490\tbest: 0.4464921 (11)\ttotal: 3m 34s\tremaining: 3m 7s\n",
      "\n",
      "bestTest = 0.4261547293\n",
      "bestIteration = 199\n",
      "\n",
      "16:\tloss: 0.4261547\tbest: 0.4261547 (16)\ttotal: 3m 59s\tremaining: 3m 2s\n",
      "\n",
      "bestTest = 0.6009202077\n",
      "bestIteration = 125\n",
      "\n",
      "17:\tloss: 0.6009202\tbest: 0.4261547 (16)\ttotal: 4m 22s\tremaining: 2m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 9.609378409\n",
      "bestIteration = 0\n",
      "\n",
      "18:\tloss: 9.6093784\tbest: 0.4261547 (16)\ttotal: 4m 47s\tremaining: 2m 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 96.03227356\n",
      "bestIteration = 0\n",
      "\n",
      "19:\tloss: 96.0322736\tbest: 0.4261547 (16)\ttotal: 5m 12s\tremaining: 2m 36s\n",
      "\n",
      "bestTest = 0.779607983\n",
      "bestIteration = 249\n",
      "\n",
      "20:\tloss: 0.7796080\tbest: 0.4261547 (16)\ttotal: 5m 43s\tremaining: 2m 27s\n",
      "\n",
      "bestTest = 0.4117861895\n",
      "bestIteration = 249\n",
      "\n",
      "21:\tloss: 0.4117862\tbest: 0.4117862 (21)\ttotal: 6m 14s\tremaining: 2m 16s\n",
      "\n",
      "bestTest = 0.6009202077\n",
      "bestIteration = 125\n",
      "\n",
      "22:\tloss: 0.6009202\tbest: 0.4117862 (21)\ttotal: 6m 44s\tremaining: 2m 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 9.609378409\n",
      "bestIteration = 0\n",
      "\n",
      "23:\tloss: 9.6093784\tbest: 0.4117862 (21)\ttotal: 7m 16s\tremaining: 1m 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 96.03227356\n",
      "bestIteration = 0\n",
      "\n",
      "24:\tloss: 96.0322736\tbest: 0.4117862 (21)\ttotal: 7m 46s\tremaining: 1m 33s\n",
      "\n",
      "bestTest = 0.7230278745\n",
      "bestIteration = 299\n",
      "\n",
      "25:\tloss: 0.7230279\tbest: 0.4117862 (21)\ttotal: 8m 24s\tremaining: 1m 17s\n",
      "\n",
      "bestTest = 0.402563924\n",
      "bestIteration = 298\n",
      "\n",
      "26:\tloss: 0.4025639\tbest: 0.4025639 (26)\ttotal: 9m\tremaining: 1m\n",
      "\n",
      "bestTest = 0.6009202077\n",
      "bestIteration = 125\n",
      "\n",
      "27:\tloss: 0.6009202\tbest: 0.4025639 (26)\ttotal: 9m 36s\tremaining: 41.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 9.609378409\n",
      "bestIteration = 0\n",
      "\n",
      "28:\tloss: 9.6093784\tbest: 0.4025639 (26)\ttotal: 10m 12s\tremaining: 21.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 96.03227356\n",
      "bestIteration = 0\n",
      "\n",
      "29:\tloss: 96.0322736\tbest: 0.4025639 (26)\ttotal: 10m 49s\tremaining: 0us\n",
      "Estimating final quality...\n"
     ]
    }
   ],
   "source": [
    "bst = catboost.CatBoostClassifier()\n",
    "grid_search_result = bst.grid_search({'learning_rate':np.logspace(-2, 2, 5), 'iterations':np.arange(50, 301, 50)},\n",
    "                                     X=x_train_new[ind], y=y_train[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 300, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_params = grid_search_result['params']\n",
    "search_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.9113553\ttotal: 4.35s\tremaining: 21m 41s\n",
      "1:\tlearn: 1.6853523\ttotal: 8.75s\tremaining: 21m 44s\n",
      "2:\tlearn: 1.5218125\ttotal: 12.5s\tremaining: 20m 34s\n",
      "3:\tlearn: 1.3927017\ttotal: 16.1s\tremaining: 19m 53s\n",
      "4:\tlearn: 1.2920560\ttotal: 19.7s\tremaining: 19m 24s\n",
      "5:\tlearn: 1.2095348\ttotal: 23.4s\tremaining: 19m 6s\n",
      "6:\tlearn: 1.1383237\ttotal: 27.2s\tremaining: 18m 58s\n",
      "7:\tlearn: 1.0750241\ttotal: 30.9s\tremaining: 18m 49s\n",
      "8:\tlearn: 1.0238835\ttotal: 34.7s\tremaining: 18m 40s\n",
      "9:\tlearn: 0.9718917\ttotal: 38.4s\tremaining: 18m 34s\n",
      "10:\tlearn: 0.9304233\ttotal: 42.3s\tremaining: 18m 30s\n",
      "11:\tlearn: 0.8940073\ttotal: 46s\tremaining: 18m 24s\n",
      "12:\tlearn: 0.8593684\ttotal: 49.7s\tremaining: 18m 18s\n",
      "13:\tlearn: 0.8288367\ttotal: 53.4s\tremaining: 18m 11s\n",
      "14:\tlearn: 0.7991806\ttotal: 57.2s\tremaining: 18m 5s\n",
      "15:\tlearn: 0.7748049\ttotal: 1m\tremaining: 18m 1s\n",
      "16:\tlearn: 0.7522235\ttotal: 1m 4s\tremaining: 17m 58s\n",
      "17:\tlearn: 0.7311923\ttotal: 1m 8s\tremaining: 17m 53s\n",
      "18:\tlearn: 0.7141401\ttotal: 1m 12s\tremaining: 17m 48s\n",
      "19:\tlearn: 0.6928643\ttotal: 1m 16s\tremaining: 17m 46s\n",
      "20:\tlearn: 0.6750442\ttotal: 1m 20s\tremaining: 17m 44s\n",
      "21:\tlearn: 0.6596829\ttotal: 1m 23s\tremaining: 17m 37s\n",
      "22:\tlearn: 0.6455604\ttotal: 1m 27s\tremaining: 17m 31s\n",
      "23:\tlearn: 0.6337224\ttotal: 1m 30s\tremaining: 17m 26s\n",
      "24:\tlearn: 0.6193214\ttotal: 1m 34s\tremaining: 17m 22s\n",
      "25:\tlearn: 0.6072870\ttotal: 1m 38s\tremaining: 17m 17s\n",
      "26:\tlearn: 0.5981192\ttotal: 1m 42s\tremaining: 17m 11s\n",
      "27:\tlearn: 0.5881777\ttotal: 1m 45s\tremaining: 17m 6s\n",
      "28:\tlearn: 0.5805686\ttotal: 1m 49s\tremaining: 17m\n",
      "29:\tlearn: 0.5721320\ttotal: 1m 52s\tremaining: 16m 56s\n",
      "30:\tlearn: 0.5630206\ttotal: 1m 56s\tremaining: 16m 52s\n",
      "31:\tlearn: 0.5563920\ttotal: 2m\tremaining: 16m 47s\n",
      "32:\tlearn: 0.5495689\ttotal: 2m 4s\tremaining: 16m 43s\n",
      "33:\tlearn: 0.5426527\ttotal: 2m 7s\tremaining: 16m 39s\n",
      "34:\tlearn: 0.5359186\ttotal: 2m 11s\tremaining: 16m 35s\n",
      "35:\tlearn: 0.5294724\ttotal: 2m 15s\tremaining: 16m 30s\n",
      "36:\tlearn: 0.5234235\ttotal: 2m 18s\tremaining: 16m 23s\n",
      "37:\tlearn: 0.5181987\ttotal: 2m 21s\tremaining: 16m 17s\n",
      "38:\tlearn: 0.5123014\ttotal: 2m 25s\tremaining: 16m 12s\n",
      "39:\tlearn: 0.5076011\ttotal: 2m 28s\tremaining: 16m 7s\n",
      "40:\tlearn: 0.5024695\ttotal: 2m 32s\tremaining: 16m 2s\n",
      "41:\tlearn: 0.4981767\ttotal: 2m 35s\tremaining: 15m 56s\n",
      "42:\tlearn: 0.4945684\ttotal: 2m 39s\tremaining: 15m 51s\n",
      "43:\tlearn: 0.4902685\ttotal: 2m 42s\tremaining: 15m 45s\n",
      "44:\tlearn: 0.4872213\ttotal: 2m 45s\tremaining: 15m 39s\n",
      "45:\tlearn: 0.4823346\ttotal: 2m 49s\tremaining: 15m 33s\n",
      "46:\tlearn: 0.4801211\ttotal: 2m 52s\tremaining: 15m 27s\n",
      "47:\tlearn: 0.4761610\ttotal: 2m 55s\tremaining: 15m 22s\n",
      "48:\tlearn: 0.4737138\ttotal: 2m 58s\tremaining: 15m 16s\n",
      "49:\tlearn: 0.4713355\ttotal: 3m 2s\tremaining: 15m 11s\n",
      "50:\tlearn: 0.4679233\ttotal: 3m 5s\tremaining: 15m 5s\n",
      "51:\tlearn: 0.4648951\ttotal: 3m 8s\tremaining: 14m 59s\n",
      "52:\tlearn: 0.4622570\ttotal: 3m 11s\tremaining: 14m 54s\n",
      "53:\tlearn: 0.4599859\ttotal: 3m 15s\tremaining: 14m 48s\n",
      "54:\tlearn: 0.4574622\ttotal: 3m 18s\tremaining: 14m 43s\n",
      "55:\tlearn: 0.4552866\ttotal: 3m 21s\tremaining: 14m 37s\n",
      "56:\tlearn: 0.4524893\ttotal: 3m 24s\tremaining: 14m 32s\n",
      "57:\tlearn: 0.4496700\ttotal: 3m 27s\tremaining: 14m 26s\n",
      "58:\tlearn: 0.4477592\ttotal: 3m 30s\tremaining: 14m 21s\n",
      "59:\tlearn: 0.4444127\ttotal: 3m 34s\tremaining: 14m 17s\n",
      "60:\tlearn: 0.4422266\ttotal: 3m 37s\tremaining: 14m 12s\n",
      "61:\tlearn: 0.4389907\ttotal: 3m 40s\tremaining: 14m 7s\n",
      "62:\tlearn: 0.4364886\ttotal: 3m 43s\tremaining: 14m 2s\n",
      "63:\tlearn: 0.4336597\ttotal: 3m 47s\tremaining: 13m 58s\n",
      "64:\tlearn: 0.4319420\ttotal: 3m 50s\tremaining: 13m 53s\n",
      "65:\tlearn: 0.4294480\ttotal: 3m 54s\tremaining: 13m 50s\n",
      "66:\tlearn: 0.4267324\ttotal: 3m 57s\tremaining: 13m 45s\n",
      "67:\tlearn: 0.4247912\ttotal: 4m\tremaining: 13m 41s\n",
      "68:\tlearn: 0.4230589\ttotal: 4m 4s\tremaining: 13m 37s\n",
      "69:\tlearn: 0.4209851\ttotal: 4m 7s\tremaining: 13m 33s\n",
      "70:\tlearn: 0.4199015\ttotal: 4m 10s\tremaining: 13m 28s\n",
      "71:\tlearn: 0.4173766\ttotal: 4m 14s\tremaining: 13m 24s\n",
      "72:\tlearn: 0.4155895\ttotal: 4m 17s\tremaining: 13m 20s\n",
      "73:\tlearn: 0.4140887\ttotal: 4m 20s\tremaining: 13m 16s\n",
      "74:\tlearn: 0.4122467\ttotal: 4m 24s\tremaining: 13m 12s\n",
      "75:\tlearn: 0.4111607\ttotal: 4m 27s\tremaining: 13m 7s\n",
      "76:\tlearn: 0.4101348\ttotal: 4m 30s\tremaining: 13m 3s\n",
      "77:\tlearn: 0.4087674\ttotal: 4m 33s\tremaining: 12m 59s\n",
      "78:\tlearn: 0.4070384\ttotal: 4m 37s\tremaining: 12m 55s\n",
      "79:\tlearn: 0.4061898\ttotal: 4m 40s\tremaining: 12m 51s\n",
      "80:\tlearn: 0.4041520\ttotal: 4m 43s\tremaining: 12m 47s\n",
      "81:\tlearn: 0.4026936\ttotal: 4m 47s\tremaining: 12m 43s\n",
      "82:\tlearn: 0.4008836\ttotal: 4m 50s\tremaining: 12m 40s\n",
      "83:\tlearn: 0.3992019\ttotal: 4m 54s\tremaining: 12m 37s\n",
      "84:\tlearn: 0.3980417\ttotal: 4m 57s\tremaining: 12m 32s\n",
      "85:\tlearn: 0.3964630\ttotal: 5m 1s\tremaining: 12m 29s\n",
      "86:\tlearn: 0.3952661\ttotal: 5m 4s\tremaining: 12m 25s\n",
      "87:\tlearn: 0.3940292\ttotal: 5m 7s\tremaining: 12m 21s\n",
      "88:\tlearn: 0.3925457\ttotal: 5m 10s\tremaining: 12m 17s\n",
      "89:\tlearn: 0.3912861\ttotal: 5m 14s\tremaining: 12m 13s\n",
      "90:\tlearn: 0.3897335\ttotal: 5m 17s\tremaining: 12m 9s\n",
      "91:\tlearn: 0.3885541\ttotal: 5m 20s\tremaining: 12m 5s\n",
      "92:\tlearn: 0.3877105\ttotal: 5m 24s\tremaining: 12m 1s\n",
      "93:\tlearn: 0.3866539\ttotal: 5m 27s\tremaining: 11m 57s\n",
      "94:\tlearn: 0.3857108\ttotal: 5m 30s\tremaining: 11m 53s\n",
      "95:\tlearn: 0.3842497\ttotal: 5m 33s\tremaining: 11m 49s\n",
      "96:\tlearn: 0.3833133\ttotal: 5m 37s\tremaining: 11m 45s\n",
      "97:\tlearn: 0.3825445\ttotal: 5m 40s\tremaining: 11m 41s\n",
      "98:\tlearn: 0.3815810\ttotal: 5m 43s\tremaining: 11m 37s\n",
      "99:\tlearn: 0.3810338\ttotal: 5m 46s\tremaining: 11m 33s\n",
      "100:\tlearn: 0.3791935\ttotal: 5m 50s\tremaining: 11m 29s\n",
      "101:\tlearn: 0.3782157\ttotal: 5m 53s\tremaining: 11m 26s\n",
      "102:\tlearn: 0.3767534\ttotal: 5m 56s\tremaining: 11m 22s\n",
      "103:\tlearn: 0.3751885\ttotal: 6m\tremaining: 11m 18s\n",
      "104:\tlearn: 0.3745318\ttotal: 6m 3s\tremaining: 11m 14s\n",
      "105:\tlearn: 0.3735556\ttotal: 6m 6s\tremaining: 11m 11s\n",
      "106:\tlearn: 0.3722244\ttotal: 6m 10s\tremaining: 11m 7s\n",
      "107:\tlearn: 0.3705559\ttotal: 6m 13s\tremaining: 11m 4s\n",
      "108:\tlearn: 0.3695638\ttotal: 6m 17s\tremaining: 11m\n",
      "109:\tlearn: 0.3686958\ttotal: 6m 20s\tremaining: 10m 57s\n",
      "110:\tlearn: 0.3679488\ttotal: 6m 23s\tremaining: 10m 53s\n",
      "111:\tlearn: 0.3666929\ttotal: 6m 27s\tremaining: 10m 50s\n",
      "112:\tlearn: 0.3652241\ttotal: 6m 30s\tremaining: 10m 46s\n",
      "113:\tlearn: 0.3644903\ttotal: 6m 33s\tremaining: 10m 42s\n",
      "114:\tlearn: 0.3633210\ttotal: 6m 37s\tremaining: 10m 39s\n",
      "115:\tlearn: 0.3622702\ttotal: 6m 40s\tremaining: 10m 35s\n",
      "116:\tlearn: 0.3614196\ttotal: 6m 43s\tremaining: 10m 31s\n",
      "117:\tlearn: 0.3604332\ttotal: 6m 47s\tremaining: 10m 27s\n",
      "118:\tlearn: 0.3595735\ttotal: 6m 50s\tremaining: 10m 24s\n",
      "119:\tlearn: 0.3588161\ttotal: 6m 53s\tremaining: 10m 20s\n",
      "120:\tlearn: 0.3578756\ttotal: 6m 56s\tremaining: 10m 16s\n",
      "121:\tlearn: 0.3571745\ttotal: 7m\tremaining: 10m 12s\n",
      "122:\tlearn: 0.3562927\ttotal: 7m 3s\tremaining: 10m 9s\n",
      "123:\tlearn: 0.3547799\ttotal: 7m 6s\tremaining: 10m 5s\n",
      "124:\tlearn: 0.3537179\ttotal: 7m 10s\tremaining: 10m 2s\n",
      "125:\tlearn: 0.3528671\ttotal: 7m 13s\tremaining: 9m 58s\n",
      "126:\tlearn: 0.3524434\ttotal: 7m 16s\tremaining: 9m 54s\n",
      "127:\tlearn: 0.3517926\ttotal: 7m 19s\tremaining: 9m 50s\n",
      "128:\tlearn: 0.3503888\ttotal: 7m 23s\tremaining: 9m 47s\n",
      "129:\tlearn: 0.3497088\ttotal: 7m 26s\tremaining: 9m 43s\n",
      "130:\tlearn: 0.3489423\ttotal: 7m 29s\tremaining: 9m 39s\n",
      "131:\tlearn: 0.3483876\ttotal: 7m 32s\tremaining: 9m 36s\n",
      "132:\tlearn: 0.3472949\ttotal: 7m 35s\tremaining: 9m 32s\n",
      "133:\tlearn: 0.3467549\ttotal: 7m 39s\tremaining: 9m 28s\n",
      "134:\tlearn: 0.3458807\ttotal: 7m 42s\tremaining: 9m 25s\n",
      "135:\tlearn: 0.3451088\ttotal: 7m 45s\tremaining: 9m 21s\n",
      "136:\tlearn: 0.3443690\ttotal: 7m 48s\tremaining: 9m 17s\n",
      "137:\tlearn: 0.3434191\ttotal: 7m 52s\tremaining: 9m 14s\n",
      "138:\tlearn: 0.3427644\ttotal: 7m 55s\tremaining: 9m 10s\n",
      "139:\tlearn: 0.3415306\ttotal: 7m 58s\tremaining: 9m 7s\n",
      "140:\tlearn: 0.3407317\ttotal: 8m 2s\tremaining: 9m 3s\n",
      "141:\tlearn: 0.3403003\ttotal: 8m 5s\tremaining: 9m\n",
      "142:\tlearn: 0.3399699\ttotal: 8m 8s\tremaining: 8m 56s\n",
      "143:\tlearn: 0.3393073\ttotal: 8m 11s\tremaining: 8m 52s\n",
      "144:\tlearn: 0.3388634\ttotal: 8m 15s\tremaining: 8m 49s\n",
      "145:\tlearn: 0.3383774\ttotal: 8m 18s\tremaining: 8m 45s\n",
      "146:\tlearn: 0.3381158\ttotal: 8m 21s\tremaining: 8m 41s\n",
      "147:\tlearn: 0.3376325\ttotal: 8m 24s\tremaining: 8m 38s\n",
      "148:\tlearn: 0.3372182\ttotal: 8m 27s\tremaining: 8m 34s\n",
      "149:\tlearn: 0.3364436\ttotal: 8m 30s\tremaining: 8m 30s\n",
      "150:\tlearn: 0.3358188\ttotal: 8m 33s\tremaining: 8m 27s\n",
      "151:\tlearn: 0.3350238\ttotal: 8m 37s\tremaining: 8m 23s\n",
      "152:\tlearn: 0.3341602\ttotal: 8m 40s\tremaining: 8m 20s\n",
      "153:\tlearn: 0.3333262\ttotal: 8m 43s\tremaining: 8m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154:\tlearn: 0.3322996\ttotal: 8m 47s\tremaining: 8m 13s\n",
      "155:\tlearn: 0.3318208\ttotal: 8m 50s\tremaining: 8m 9s\n",
      "156:\tlearn: 0.3308251\ttotal: 8m 53s\tremaining: 8m 6s\n",
      "157:\tlearn: 0.3298949\ttotal: 8m 56s\tremaining: 8m 2s\n",
      "158:\tlearn: 0.3288581\ttotal: 9m\tremaining: 7m 59s\n",
      "159:\tlearn: 0.3284808\ttotal: 9m 3s\tremaining: 7m 55s\n",
      "160:\tlearn: 0.3276723\ttotal: 9m 6s\tremaining: 7m 52s\n",
      "161:\tlearn: 0.3270298\ttotal: 9m 10s\tremaining: 7m 48s\n",
      "162:\tlearn: 0.3265172\ttotal: 9m 13s\tremaining: 7m 45s\n",
      "163:\tlearn: 0.3260924\ttotal: 9m 16s\tremaining: 7m 41s\n",
      "164:\tlearn: 0.3258680\ttotal: 9m 19s\tremaining: 7m 37s\n",
      "165:\tlearn: 0.3254831\ttotal: 9m 22s\tremaining: 7m 34s\n",
      "166:\tlearn: 0.3250574\ttotal: 9m 25s\tremaining: 7m 30s\n",
      "167:\tlearn: 0.3244064\ttotal: 9m 28s\tremaining: 7m 27s\n",
      "168:\tlearn: 0.3235291\ttotal: 9m 32s\tremaining: 7m 23s\n",
      "169:\tlearn: 0.3231744\ttotal: 9m 35s\tremaining: 7m 19s\n",
      "170:\tlearn: 0.3225392\ttotal: 9m 38s\tremaining: 7m 16s\n",
      "171:\tlearn: 0.3221578\ttotal: 9m 41s\tremaining: 7m 12s\n",
      "172:\tlearn: 0.3212146\ttotal: 9m 45s\tremaining: 7m 9s\n",
      "173:\tlearn: 0.3207681\ttotal: 9m 48s\tremaining: 7m 6s\n",
      "174:\tlearn: 0.3202398\ttotal: 9m 51s\tremaining: 7m 2s\n",
      "175:\tlearn: 0.3196748\ttotal: 9m 55s\tremaining: 6m 59s\n",
      "176:\tlearn: 0.3189074\ttotal: 9m 58s\tremaining: 6m 55s\n",
      "177:\tlearn: 0.3179332\ttotal: 10m 2s\tremaining: 6m 52s\n",
      "178:\tlearn: 0.3173207\ttotal: 10m 5s\tremaining: 6m 49s\n",
      "179:\tlearn: 0.3167093\ttotal: 10m 8s\tremaining: 6m 45s\n",
      "180:\tlearn: 0.3160112\ttotal: 10m 11s\tremaining: 6m 42s\n",
      "181:\tlearn: 0.3158045\ttotal: 10m 14s\tremaining: 6m 38s\n",
      "182:\tlearn: 0.3152735\ttotal: 10m 17s\tremaining: 6m 35s\n",
      "183:\tlearn: 0.3149780\ttotal: 10m 21s\tremaining: 6m 31s\n",
      "184:\tlearn: 0.3145077\ttotal: 10m 24s\tremaining: 6m 28s\n",
      "185:\tlearn: 0.3143335\ttotal: 10m 27s\tremaining: 6m 24s\n",
      "186:\tlearn: 0.3138917\ttotal: 10m 30s\tremaining: 6m 20s\n",
      "187:\tlearn: 0.3134424\ttotal: 10m 33s\tremaining: 6m 17s\n",
      "188:\tlearn: 0.3129090\ttotal: 10m 36s\tremaining: 6m 13s\n",
      "189:\tlearn: 0.3124801\ttotal: 10m 39s\tremaining: 6m 10s\n",
      "190:\tlearn: 0.3123023\ttotal: 10m 42s\tremaining: 6m 6s\n",
      "191:\tlearn: 0.3115104\ttotal: 10m 46s\tremaining: 6m 3s\n",
      "192:\tlearn: 0.3113713\ttotal: 10m 49s\tremaining: 5m 59s\n",
      "193:\tlearn: 0.3111148\ttotal: 10m 52s\tremaining: 5m 56s\n",
      "194:\tlearn: 0.3105842\ttotal: 10m 55s\tremaining: 5m 52s\n",
      "195:\tlearn: 0.3098566\ttotal: 10m 58s\tremaining: 5m 49s\n",
      "196:\tlearn: 0.3092500\ttotal: 11m 2s\tremaining: 5m 46s\n",
      "197:\tlearn: 0.3087752\ttotal: 11m 5s\tremaining: 5m 42s\n",
      "198:\tlearn: 0.3081898\ttotal: 11m 8s\tremaining: 5m 39s\n",
      "199:\tlearn: 0.3078591\ttotal: 11m 11s\tremaining: 5m 35s\n",
      "200:\tlearn: 0.3073352\ttotal: 11m 14s\tremaining: 5m 32s\n",
      "201:\tlearn: 0.3069382\ttotal: 11m 17s\tremaining: 5m 28s\n",
      "202:\tlearn: 0.3063749\ttotal: 11m 21s\tremaining: 5m 25s\n",
      "203:\tlearn: 0.3059593\ttotal: 11m 24s\tremaining: 5m 21s\n",
      "204:\tlearn: 0.3055587\ttotal: 11m 27s\tremaining: 5m 18s\n",
      "205:\tlearn: 0.3052255\ttotal: 11m 30s\tremaining: 5m 15s\n",
      "206:\tlearn: 0.3048361\ttotal: 11m 33s\tremaining: 5m 11s\n",
      "207:\tlearn: 0.3045941\ttotal: 11m 36s\tremaining: 5m 8s\n",
      "208:\tlearn: 0.3038154\ttotal: 11m 40s\tremaining: 5m 4s\n",
      "209:\tlearn: 0.3030436\ttotal: 11m 43s\tremaining: 5m 1s\n",
      "210:\tlearn: 0.3027984\ttotal: 11m 46s\tremaining: 4m 57s\n",
      "211:\tlearn: 0.3020515\ttotal: 11m 49s\tremaining: 4m 54s\n",
      "212:\tlearn: 0.3017252\ttotal: 11m 52s\tremaining: 4m 51s\n",
      "213:\tlearn: 0.3014169\ttotal: 11m 55s\tremaining: 4m 47s\n",
      "214:\tlearn: 0.3012020\ttotal: 11m 58s\tremaining: 4m 44s\n",
      "215:\tlearn: 0.3007898\ttotal: 12m 2s\tremaining: 4m 40s\n",
      "216:\tlearn: 0.3005492\ttotal: 12m 5s\tremaining: 4m 37s\n",
      "217:\tlearn: 0.3000022\ttotal: 12m 8s\tremaining: 4m 33s\n",
      "218:\tlearn: 0.2996635\ttotal: 12m 11s\tremaining: 4m 30s\n",
      "219:\tlearn: 0.2994020\ttotal: 12m 14s\tremaining: 4m 27s\n",
      "220:\tlearn: 0.2990875\ttotal: 12m 18s\tremaining: 4m 23s\n",
      "221:\tlearn: 0.2985712\ttotal: 12m 21s\tremaining: 4m 20s\n",
      "222:\tlearn: 0.2979404\ttotal: 12m 24s\tremaining: 4m 17s\n",
      "223:\tlearn: 0.2975666\ttotal: 12m 27s\tremaining: 4m 13s\n",
      "224:\tlearn: 0.2973071\ttotal: 12m 30s\tremaining: 4m 10s\n",
      "225:\tlearn: 0.2966182\ttotal: 12m 33s\tremaining: 4m 6s\n",
      "226:\tlearn: 0.2959336\ttotal: 12m 37s\tremaining: 4m 3s\n",
      "227:\tlearn: 0.2955951\ttotal: 12m 40s\tremaining: 4m\n",
      "228:\tlearn: 0.2950802\ttotal: 12m 43s\tremaining: 3m 56s\n",
      "229:\tlearn: 0.2944095\ttotal: 12m 47s\tremaining: 3m 53s\n",
      "230:\tlearn: 0.2939805\ttotal: 12m 50s\tremaining: 3m 50s\n",
      "231:\tlearn: 0.2935485\ttotal: 12m 53s\tremaining: 3m 46s\n",
      "232:\tlearn: 0.2930525\ttotal: 12m 56s\tremaining: 3m 43s\n",
      "233:\tlearn: 0.2925312\ttotal: 12m 59s\tremaining: 3m 39s\n",
      "234:\tlearn: 0.2922163\ttotal: 13m 3s\tremaining: 3m 36s\n",
      "235:\tlearn: 0.2918979\ttotal: 13m 6s\tremaining: 3m 33s\n",
      "236:\tlearn: 0.2917421\ttotal: 13m 9s\tremaining: 3m 29s\n",
      "237:\tlearn: 0.2914780\ttotal: 13m 12s\tremaining: 3m 26s\n",
      "238:\tlearn: 0.2911835\ttotal: 13m 15s\tremaining: 3m 23s\n",
      "239:\tlearn: 0.2905847\ttotal: 13m 18s\tremaining: 3m 19s\n",
      "240:\tlearn: 0.2902326\ttotal: 13m 21s\tremaining: 3m 16s\n",
      "241:\tlearn: 0.2898091\ttotal: 13m 25s\tremaining: 3m 12s\n",
      "242:\tlearn: 0.2892846\ttotal: 13m 28s\tremaining: 3m 9s\n",
      "243:\tlearn: 0.2891034\ttotal: 13m 31s\tremaining: 3m 6s\n",
      "244:\tlearn: 0.2887711\ttotal: 13m 34s\tremaining: 3m 2s\n",
      "245:\tlearn: 0.2885807\ttotal: 13m 37s\tremaining: 2m 59s\n",
      "246:\tlearn: 0.2882909\ttotal: 13m 40s\tremaining: 2m 56s\n",
      "247:\tlearn: 0.2880287\ttotal: 13m 43s\tremaining: 2m 52s\n",
      "248:\tlearn: 0.2877882\ttotal: 13m 47s\tremaining: 2m 49s\n",
      "249:\tlearn: 0.2873826\ttotal: 13m 50s\tremaining: 2m 46s\n",
      "250:\tlearn: 0.2870913\ttotal: 13m 53s\tremaining: 2m 42s\n",
      "251:\tlearn: 0.2868290\ttotal: 13m 56s\tremaining: 2m 39s\n",
      "252:\tlearn: 0.2866119\ttotal: 13m 59s\tremaining: 2m 35s\n",
      "253:\tlearn: 0.2860657\ttotal: 14m 2s\tremaining: 2m 32s\n",
      "254:\tlearn: 0.2855409\ttotal: 14m 6s\tremaining: 2m 29s\n",
      "255:\tlearn: 0.2854090\ttotal: 14m 9s\tremaining: 2m 25s\n",
      "256:\tlearn: 0.2849354\ttotal: 14m 12s\tremaining: 2m 22s\n",
      "257:\tlearn: 0.2844475\ttotal: 14m 15s\tremaining: 2m 19s\n",
      "258:\tlearn: 0.2842736\ttotal: 14m 18s\tremaining: 2m 15s\n",
      "259:\tlearn: 0.2836369\ttotal: 14m 22s\tremaining: 2m 12s\n",
      "260:\tlearn: 0.2834261\ttotal: 14m 25s\tremaining: 2m 9s\n",
      "261:\tlearn: 0.2832172\ttotal: 14m 28s\tremaining: 2m 5s\n",
      "262:\tlearn: 0.2830967\ttotal: 14m 31s\tremaining: 2m 2s\n",
      "263:\tlearn: 0.2828678\ttotal: 14m 34s\tremaining: 1m 59s\n",
      "264:\tlearn: 0.2823187\ttotal: 14m 37s\tremaining: 1m 55s\n",
      "265:\tlearn: 0.2817557\ttotal: 14m 40s\tremaining: 1m 52s\n",
      "266:\tlearn: 0.2815681\ttotal: 14m 44s\tremaining: 1m 49s\n",
      "267:\tlearn: 0.2809868\ttotal: 14m 47s\tremaining: 1m 45s\n",
      "268:\tlearn: 0.2808558\ttotal: 14m 50s\tremaining: 1m 42s\n",
      "269:\tlearn: 0.2805674\ttotal: 14m 53s\tremaining: 1m 39s\n",
      "270:\tlearn: 0.2804200\ttotal: 14m 57s\tremaining: 1m 35s\n",
      "271:\tlearn: 0.2801817\ttotal: 15m\tremaining: 1m 32s\n",
      "272:\tlearn: 0.2799033\ttotal: 15m 3s\tremaining: 1m 29s\n",
      "273:\tlearn: 0.2796233\ttotal: 15m 6s\tremaining: 1m 26s\n",
      "274:\tlearn: 0.2793276\ttotal: 15m 9s\tremaining: 1m 22s\n",
      "275:\tlearn: 0.2791244\ttotal: 15m 12s\tremaining: 1m 19s\n",
      "276:\tlearn: 0.2788711\ttotal: 15m 15s\tremaining: 1m 16s\n",
      "277:\tlearn: 0.2786517\ttotal: 15m 19s\tremaining: 1m 12s\n",
      "278:\tlearn: 0.2784037\ttotal: 15m 22s\tremaining: 1m 9s\n",
      "279:\tlearn: 0.2781239\ttotal: 15m 25s\tremaining: 1m 6s\n",
      "280:\tlearn: 0.2776881\ttotal: 15m 28s\tremaining: 1m 2s\n",
      "281:\tlearn: 0.2773854\ttotal: 15m 31s\tremaining: 59.5s\n",
      "282:\tlearn: 0.2771979\ttotal: 15m 35s\tremaining: 56.2s\n",
      "283:\tlearn: 0.2770246\ttotal: 15m 38s\tremaining: 52.9s\n",
      "284:\tlearn: 0.2767264\ttotal: 15m 41s\tremaining: 49.5s\n",
      "285:\tlearn: 0.2766148\ttotal: 15m 44s\tremaining: 46.2s\n",
      "286:\tlearn: 0.2763960\ttotal: 15m 47s\tremaining: 42.9s\n",
      "287:\tlearn: 0.2763433\ttotal: 15m 50s\tremaining: 39.6s\n",
      "288:\tlearn: 0.2758763\ttotal: 15m 53s\tremaining: 36.3s\n",
      "289:\tlearn: 0.2756096\ttotal: 15m 56s\tremaining: 33s\n",
      "290:\tlearn: 0.2754637\ttotal: 15m 59s\tremaining: 29.7s\n",
      "291:\tlearn: 0.2750170\ttotal: 16m 3s\tremaining: 26.4s\n",
      "292:\tlearn: 0.2743925\ttotal: 16m 6s\tremaining: 23.1s\n",
      "293:\tlearn: 0.2739092\ttotal: 16m 9s\tremaining: 19.8s\n",
      "294:\tlearn: 0.2734657\ttotal: 16m 12s\tremaining: 16.5s\n",
      "295:\tlearn: 0.2729606\ttotal: 16m 15s\tremaining: 13.2s\n",
      "296:\tlearn: 0.2724943\ttotal: 16m 19s\tremaining: 9.89s\n",
      "297:\tlearn: 0.2722090\ttotal: 16m 22s\tremaining: 6.59s\n",
      "298:\tlearn: 0.2720712\ttotal: 16m 25s\tremaining: 3.29s\n",
      "299:\tlearn: 0.2717164\ttotal: 16m 28s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x13187b4e708>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst = catboost.CatBoostClassifier(iterations=search_params['iterations'],\n",
    "                                  learning_rate=search_params['learning_rate'])\n",
    "bst.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, bst.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "300 деревьев, 16 минут... Стоило ли оно 2% аккураси? Вопрос, достойный размышления...(нет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA?\n",
    "\n",
    "Это точно помогает, без него вообще не рабит (аккураси падает с 85% до 10%)\n",
    "\n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "\n",
    "Оно растет до какого-то момента, потом выходит на плато. Ну и начинает немного шуметь.\n",
    "\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?\n",
    "\n",
    "Получилось, что важно. Качество дают схожее (но в нашем случае логрег получше почему-то справился), а вот время обучения отличается кардинально (свм сас). Время предсказаний (бдмсссс) еще кардинальней)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time: 6.818558216094971 sec\n",
      "accuracy: 0.8514\n",
      "fit time: 0.40403008460998535 sec\n"
     ]
    }
   ],
   "source": [
    "#RFF на logreg\n",
    "clf = RFFPipeline()\n",
    "start_time = time.time()\n",
    "clf.fit(x_train[ind], y_train[ind])\n",
    "print(f'fit time: {time.time() - start_time} sec')\n",
    "start_time = time.time()\n",
    "print(f'accuracy: {accuracy_score(y_test, clf.predict(x_test))}')\n",
    "print(f'fit time: {time.time() - start_time} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n",
      "fit time: 4.796139717102051 sec\n",
      "accuracy: 0.1034\n",
      "fit time: 0.6040472984313965 sec\n"
     ]
    }
   ],
   "source": [
    "#RFF на logreg без понижения размерности\n",
    "clf = RFFPipeline(use_PCA=False)\n",
    "start_time = time.time()\n",
    "clf.fit(x_train[ind], y_train[ind])\n",
    "print(f'fit time: {time.time() - start_time} sec')\n",
    "start_time = time.time()\n",
    "print(f'accuracy: {accuracy_score(y_test, clf.predict(x_test))}')\n",
    "print(f'fit time: {time.time() - start_time} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n",
      "fit time: 38.20696711540222 sec\n",
      "accuracy: 0.837\n",
      "fit time: 52.111276626586914 sec\n"
     ]
    }
   ],
   "source": [
    "#RFF на SVM\n",
    "clf = RFFPipeline(classifier='svm')\n",
    "start_time = time.time()\n",
    "clf.fit(x_train[ind], y_train[ind])\n",
    "print(f'fit time: {time.time() - start_time} sec')\n",
    "start_time = time.time()\n",
    "print(f'accuracy: {accuracy_score(y_test, clf.predict(x_test))}')\n",
    "print(f'fit time: {time.time() - start_time} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "scale = np.arange(500, 2000, 100)\n",
    "for n in scale:\n",
    "    clf = RFFPipeline(n_features=n)\n",
    "    clf.fit(x_train[ind], y_train[ind])\n",
    "    accuracy.append(accuracy_score(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1319cc59048>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scale, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На картинке изображено плато. \n",
    "\n",
    "(после этих слов в горный поход со мной никто не пошел:( )\n",
    "\n",
    "Но вообще видно, что отличие в 3 знаке только, поэтому плато настало даже на n_features=500. \n",
    "\n",
    "Вот запуск для небольших n_features, видно, что в начале рост приличный, но явно замедляющийся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20770603188>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = []\n",
    "scale = np.arange(50, 200, 30)\n",
    "for n in scale:\n",
    "    clf = RFFPipeline(n_features=n)\n",
    "    clf.fit(x_train[ind], y_train[ind])\n",
    "    accuracy.append(accuracy_score(y_test, clf.predict(x_test)))\n",
    "plt.plot(scale, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class ORFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg', num_samples=int(1e6)):\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        self.num_samples = num_samples\n",
    "        self.model = None\n",
    "        self.pca = None\n",
    "        self.q = None\n",
    "        self.b = None\n",
    "        self.w = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_new = X.copy()\n",
    "        if self.use_PCA:\n",
    "            self.pca = PCA(n_components = self.new_dim)\n",
    "            X_new = self.pca.fit_transform(X)\n",
    "        else:\n",
    "            self.new_dim = X.shape[1]\n",
    "        print('PCA done!')\n",
    "        \n",
    "        ind1_ = (np.random.choice(len(X_new), self.num_samples))\n",
    "        ind2_ = (np.random.choice(len(X_new), self.num_samples))\n",
    "        ind1 = ind1_[ind1_ != ind2_]\n",
    "        ind2 = ind2_[ind1_ != ind2_]\n",
    "        self.q = np.median(((X_new[ind1] - X_new[ind2])**2).sum(axis=1))**0.5 #это сигма\n",
    "        \n",
    "        m = math.ceil(self.n_features / self.new_dim)\n",
    "        ans = []\n",
    "        for i in range(m):\n",
    "            S = np.diag(np.random.chisquare(df=self.new_dim, size=self.new_dim))\n",
    "            Q = qr(np.random.randn(self.new_dim, self.new_dim))[0]\n",
    "            ans.append(S @ Q)\n",
    "        self.w = np.concatenate(ans)[:self.n_features] / self.q\n",
    "        #self.b = np.random.uniform(low=-math.pi, high=math.pi, size=self.n_features) #это ветор весов b\n",
    "        \n",
    "        #phi = np.cos(self.w @ X_new.T + np.repeat(self.b.reshape(-1, 1), len(X_new), axis=1)).T #это итоговые новые признаки\n",
    "        phi = np.concatenate([np.cos(self.w @ X_new.T), np.sin(self.w @ X_new.T)]).T\n",
    "        \n",
    "        print('Start fitting!')\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression()\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = SVC()\n",
    "        self.model.fit(phi, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_new = X.copy()\n",
    "        if self.use_PCA:\n",
    "            X_new = self.pca.transform(X)\n",
    "        #phi = np.cos(self.w @ X_new.T + np.repeat(self.b.reshape(-1, 1), len(X_new), axis=1)).T\n",
    "        phi = np.concatenate([np.cos(self.w @ X_new.T), np.sin(self.w @ X_new.T)]).T\n",
    "        if self.classifier == 'logreg':\n",
    "            return self.model.predict_proba(phi)\n",
    "        elif self.classifier == 'svm':\n",
    "            return softmax(self.model.decision_function(phi))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X_new = X.copy()\n",
    "        if self.use_PCA:\n",
    "            X_new = self.pca.transform(X)\n",
    "        #phi = np.cos(self.w @ X_new.T + np.repeat(self.b.reshape(-1, 1), len(X_new), axis=1)).T\n",
    "        phi = np.concatenate([np.cos(self.w @ X_new.T), np.sin(self.w @ X_new.T)]).T\n",
    "        return self.model.predict(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7157"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ORFPipeline()\n",
    "clf.fit(x_train, y_train)\n",
    "accuracy_score(y_test, clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, если реализовывать без вектором сдвигов (которые b), а с синусами, то это дает улучшение аккураси на 0.03."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты.\n",
    "\n",
    "Сначала я напишу функцию по преобразованию признаков. Там будут разные режимы, вот надо на них смотреть. Дальше сам класс классификатора идентичен тому, что был выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Это будет функция преобразования исходных признаков в новые\n",
    "# mode - то, как преобразовывать (0 - RFF)\n",
    "def new_features(X, n_features, d, q, mode, params=None):\n",
    "    if mode == 0:\n",
    "        b = w = 0\n",
    "        if params is None:\n",
    "            b = np.random.uniform(low=-math.pi, high=math.pi, size=n_features)\n",
    "            w = np.random.normal(scale=1 / q, size=(n_features, d))\n",
    "        else:\n",
    "            w, b = params[0], params[1]\n",
    "        return np.cos(w @ X.T + np.repeat(b.reshape(-1, 1), len(X), axis=1)).T, (w, b)\n",
    "    elif mode == 1:\n",
    "        w = 0\n",
    "        if params is None:\n",
    "            w = np.random.normal(scale=1 / q, size=(n_features, d))\n",
    "        else:\n",
    "            w = params\n",
    "        return np.sign(w @ X.T).T, w\n",
    "    elif mode == 2:\n",
    "        w = b = 0\n",
    "        if params is None:\n",
    "            w = np.random.normal(scale=1 / q, size=(n_features, d))\n",
    "            b = np.random.normal(size = n_features)\n",
    "        else:\n",
    "            w, b = params[0], params[1]\n",
    "        return np.sign(w @ X.T + np.repeat(b.reshape(-1, 1), len(X), axis=1)).T, (w, b)\n",
    "    elif mode == 3: #лог-мономы\n",
    "        Deg = 0\n",
    "        sgn = 0\n",
    "        if params is None:\n",
    "            Deg = np.random.randint(low=0, high=10, size=(d, n_features))\n",
    "            sgn = np.random.choice([-1, 1], size=n_features)\n",
    "        else:\n",
    "            Deg, sgn = params[0], params[1]\n",
    "        return (np.log(np.abs(X)) @ Deg) * np.repeat(sgn.reshape(1, -1), len(X), axis=0), (Deg, sgn)\n",
    "    elif mode == 4: #лог-мономы со сдвигами\n",
    "        b = 0\n",
    "        Deg = 0\n",
    "        sgn = 0\n",
    "        if params is None:\n",
    "            b = np.random.normal(scale = q, size = (1, d))\n",
    "            Deg = np.random.randint(low=0, high=3, size=(d, n_features))\n",
    "            sgn = np.random.choice([-1, 1], size=(1, n_features))\n",
    "        else:\n",
    "            b, Deg, sgn = params[0], params[1], params[2]\n",
    "        return (np.log(np.abs(X + np.repeat(b, len(X), axis=0))) @ Deg) * np.repeat(sgn, len(X), axis=0), (b, Deg, sgn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "# для начала напишем класс\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class MYPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg', num_samples=int(1e6), mode=0):\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        self.num_samples = num_samples\n",
    "        self.model = None\n",
    "        self.pca = None\n",
    "        self.q = None\n",
    "        self.params = None\n",
    "        self.mode = mode\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_new = X.copy()\n",
    "        if self.use_PCA:\n",
    "            self.pca = PCA(n_components = self.new_dim)\n",
    "            X_new = self.pca.fit_transform(X)\n",
    "        else:\n",
    "            self.new_dim = X.shape[1]\n",
    "        print('PCA done!')\n",
    "        \n",
    "        ind1_ = (np.random.choice(len(X_new), self.num_samples))\n",
    "        ind2_ = (np.random.choice(len(X_new), self.num_samples))\n",
    "        ind1 = ind1_[ind1_ != ind2_]\n",
    "        ind2 = ind2_[ind1_ != ind2_]\n",
    "        self.q = np.median(((X_new[ind1] - X_new[ind2])**2).sum(axis=1))**0.5 #это сигма\n",
    "        \n",
    "        phi, self.params = new_features(X_new, self.n_features, self.new_dim, self.q, mode=self.mode)\n",
    "        \n",
    "        print('Start fitting!')\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression()\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = SVC()\n",
    "        elif self.classifier == 'boosting':\n",
    "            self.model = CatBoostClassifier(iterations=30)\n",
    "        self.model.fit(phi, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_new = X.copy()\n",
    "        if self.use_PCA:\n",
    "            X_new = self.pca.transform(X)\n",
    "        phi, _ = new_features(X_new, self.n_features, self.new_dim, self.q, mode=self.mode, params=self.params)\n",
    "        if self.classifier == 'logreg':\n",
    "            return self.model.predict_proba(phi)\n",
    "        elif self.classifier == 'svm':\n",
    "            return softmax(self.model.decision_function(phi))\n",
    "        return 0\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X_new = X.copy()\n",
    "        if self.use_PCA:\n",
    "            X_new = self.pca.transform(X)\n",
    "        phi, _ = new_features(X_new, self.n_features, self.new_dim, self.q, mode=self.mode, params=self.params)\n",
    "        return self.model.predict(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8532"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пробуем на дефолтных настройках\n",
    "clf = MYPipeline()\n",
    "clf.fit(x_train[ind], y_train[ind])\n",
    "accuracy_score(y_test, clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 1.3332630\ttotal: 3.01s\tremaining: 1m 27s\n",
      "1:\tlearn: 1.0689765\ttotal: 6.06s\tremaining: 1m 24s\n",
      "2:\tlearn: 0.9183392\ttotal: 9.04s\tremaining: 1m 21s\n",
      "3:\tlearn: 0.8242446\ttotal: 11.8s\tremaining: 1m 16s\n",
      "4:\tlearn: 0.7620043\ttotal: 14.5s\tremaining: 1m 12s\n",
      "5:\tlearn: 0.7071861\ttotal: 17s\tremaining: 1m 7s\n",
      "6:\tlearn: 0.6725813\ttotal: 19.5s\tremaining: 1m 4s\n",
      "7:\tlearn: 0.6382281\ttotal: 22.1s\tremaining: 1m\n",
      "8:\tlearn: 0.6138504\ttotal: 24.7s\tremaining: 57.5s\n",
      "9:\tlearn: 0.5961494\ttotal: 27.1s\tremaining: 54.1s\n",
      "10:\tlearn: 0.5746249\ttotal: 29.5s\tremaining: 51s\n",
      "11:\tlearn: 0.5580064\ttotal: 32s\tremaining: 48.1s\n",
      "12:\tlearn: 0.5433017\ttotal: 34.6s\tremaining: 45.3s\n",
      "13:\tlearn: 0.5284160\ttotal: 37.2s\tremaining: 42.5s\n",
      "14:\tlearn: 0.5127997\ttotal: 39.8s\tremaining: 39.8s\n",
      "15:\tlearn: 0.5002306\ttotal: 42.2s\tremaining: 36.9s\n",
      "16:\tlearn: 0.4869868\ttotal: 44.7s\tremaining: 34.2s\n",
      "17:\tlearn: 0.4816735\ttotal: 47.3s\tremaining: 31.5s\n",
      "18:\tlearn: 0.4745970\ttotal: 49.7s\tremaining: 28.8s\n",
      "19:\tlearn: 0.4679631\ttotal: 52.1s\tremaining: 26s\n",
      "20:\tlearn: 0.4628338\ttotal: 54.4s\tremaining: 23.3s\n",
      "21:\tlearn: 0.4554516\ttotal: 56.8s\tremaining: 20.7s\n",
      "22:\tlearn: 0.4475790\ttotal: 59.2s\tremaining: 18s\n",
      "23:\tlearn: 0.4404458\ttotal: 1m 1s\tremaining: 15.4s\n",
      "24:\tlearn: 0.4368014\ttotal: 1m 3s\tremaining: 12.8s\n",
      "25:\tlearn: 0.4321136\ttotal: 1m 6s\tremaining: 10.2s\n",
      "26:\tlearn: 0.4261881\ttotal: 1m 8s\tremaining: 7.63s\n",
      "27:\tlearn: 0.4210219\ttotal: 1m 11s\tremaining: 5.07s\n",
      "28:\tlearn: 0.4147469\ttotal: 1m 13s\tremaining: 2.53s\n",
      "29:\tlearn: 0.4092572\ttotal: 1m 15s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MYPipeline(classifier='boosting')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пробуем бустинг на случайных признаках\n",
    "clf = MYPipeline(classifier='boosting')\n",
    "clf.fit(x_train[ind], y_train[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7972"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf.predict(x_test))\n",
    "# бустинг на RFF - хуже (дольше и качество меньше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7945"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пробуем знак вместо косинуса и без сдвига\n",
    "clf = MYPipeline(mode=1)\n",
    "clf.fit(x_train[ind], y_train[ind])\n",
    "accuracy_score(y_test, clf.predict(x_test))\n",
    "# резы похуже, чем по умолчанию, но сравнимо с бустингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8163"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# а если к знакам добавить нормальные сдвиги?\n",
    "clf = MYPipeline(mode=2)\n",
    "clf.fit(x_train[ind], y_train[ind])\n",
    "accuracy_score(y_test, clf.predict(x_test))\n",
    "# ну на 0.02 аккураси подняли, сойдет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6111"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# логарифмированные мономы\n",
    "clf = MYPipeline(n_features=2000, new_dim=100, mode=3)\n",
    "clf.fit(x_train[ind], y_train[ind])\n",
    "accuracy_score(y_test, clf.predict(x_test))\n",
    "# чет не пошло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done!\n",
      "Start fitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danill\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.686"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# логарифмированные мономы со сдвигами\n",
    "clf = MYPipeline(n_features=2000, new_dim=100, mode=4)\n",
    "clf.fit(x_train[ind], y_train[ind])\n",
    "accuracy_score(y_test, clf.predict(x_test))\n",
    "# тоже отстойно, но лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
